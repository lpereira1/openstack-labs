---
date: "2016-10-09"
draft: false
weight: 290
title: "Lab 29 - Creating Block Storage Volumes with Cinder at the CLI"
---
[Click here to find out more about Alta3 Research's Openstack Training](https://alta3.com/courses/openstack)

### THURSDAY- &#x2B50;REQUIRED&#x2B50;

### Lab Objective 

The objective of this lab is to create a block storage volume with Cinder at the CLI, attach it to a VM instance, create some data on that volume, detach that volume, attach it to a new VM, and then confirm that the data moved with the cinder volume.

### Procedure

0. We don't need any old terminal windows open, so close them all, and then open a new one. Once you have a new terminal window open, SSH to controller. 

    `student@beachhead:/$` `ssh controller`

0. The CLI prompt should now read as follows:

    `student@controller:~$`

0. Source the chester.rc permissions file

    `student@controller:~$` `source chester.rc`

0. Create a new volume called **NASferatu** a **1 Gb** in size/

    `student@controller (chester) :~$` `openstack volume create --size 1 NASferatu`

    ![Create 1 Gb Volume](https://alta3.com/labs/images/alta3_lab_volume_create.png)

0. Based on the output, answer the following questions:

    - **Q1: Is this a bootable volume?**
      - A1: No. The value of bootable is false.
    - **Q2: Is this volume encrypted?**
      - Q2: No. The value of encrypted is false.
    - **Q3: What is the status?**
      - Q3: The status is listed as creating

0. Issue the following command to retrieve a list of cinder volumes available to the current users chestercopperpot:

    `student@controller (chester) :~$` `openstack volume list`
    
    ```
    +--------------------------------------+--------------+-----------+------+------------------------------+
    | ID                                   | Display Name | Status    | Size | Attached to                  |
    +--------------------------------------+--------------+-----------+------+------------------------------+
    | 857334ec-92ce-43dc-83b5-b801b77337c6 | NASferatu    | available |    1 |                              |
    | d37ab4c8-786e-4915-a94c-0c5ff5e3c20c | cargo-bay    | in-use    |    1 | Attached to vt2 on /dev/vdb  |
    +--------------------------------------+--------------+-----------+------+------------------------------+
    ```
    >
    You'll need to use the UUID for NASferatu in the next few steps. 
    
0. Based on the output from the previous command, *openstack volume list*, answer the following questions.
	
    - **Q1: What is the ID of NASferatu?**
      - A1: NASferatu is identified by an UUID revealed by the openstack volume list command
    - **Q2: Has the status changed?**
      - Q2: Yes. The status is now listed as available.

0. Issue the following command to retrive a list of the instances currently in operation. Note the ID of vt2.
	
    `student@controller (chester) :~$` `openstack server list`
    
    ```
    +--------------------------------------+-----------+--------+-----------------------------+
    | ID                                   | Name      | Status | Networks                    |
    +--------------------------------------+-----------+--------+-----------------------------+
    | 835a6280-7f4f-4d9a-9705-5c9b8e64a317 | vt2       | ACTIVE | vault-tek-network=10.10.0.3 |
    +--------------------------------------+-----------+--------+-----------------------------+
    ```
    >
    You'll need to use the UUID for vt2 that you just retrieved in the next few steps. 
	
0. **IMPORTANT:** You'll need to customize this step. Issue the following command to attach the new volume (NASferatu) to a VM instance (vt2)
	
    `student@controller (chester) :~$` `openstack server add volume <UUID_OF_INSTANCE_vt2> <UUID_OF_NASferatu>`
	
0. Confirm that NASferatu has been Attached to vt2
	
    `student@controller (chester) :~$` `openstack volume list`
    
    ```
    +--------------------------------------+--------------+--------+------+------------------------------+
    | ID                                   | Display Name | Status | Size | Attached to                  |
    +--------------------------------------+--------------+--------+------+------------------------------+
    | 857334ec-92ce-43dc-83b5-b801b77337c6 | NASferatu    | in-use |    1 | Attached to vt2 on /dev/vdc  |
    | d37ab4c8-786e-4915-a94c-0c5ff5e3c20c | cargo-bay    | in-use |    1 | Attached to vt2 on /dev/vdb  |
    +--------------------------------------+--------------+--------+------+------------------------------+
    ```
	
0. Issue the following command to detach the volume from vt2

    `student@controller (chester) :~$` `openstack server remove volume <UUID_OF_INSTANCE_vt2> <UUID_OF_NASferatu>`
	
0. Check on the status of the volume (NASferatu)
	
    `student@controller (chester) :~$` `openstack volume list`

    - **Q1: What is the status of NASferatu?**
      - A1: It has changed from in-use, to available.

0. Now that the volume is detached, delete it.
	
    `student@controller (chester) :~$` `openstack volume delete <UUID_OF_NASferatu>`

0. Confirm that the volume has been deleted.

    `student@controller (chester) :~$` `openstack volume list`
	
    - **Q1: What is the status of NASferatu?**
      - A1: NASferatu has been deleted and is no longer available.
    - **Q2: Can a volume be deleted when it is in-use?**
      - Q2: No. If a volume is attached to a VM, it must first be removed (detached) before it may be deleted.

0. Time to SSH into vt2 and write some data to the volume. Let's create a floating IP to apply to vt2 so that SSH is easy.

    `student@controller (chester) :~$` `openstack ip floating create provider-net`
    
    ```
    +-------------+--------------------------------------+
    | Field       | Value                                |
    +-------------+--------------------------------------+
    | fixed_ip    | None                                 |
    | id          | db2bd097-1c9b-46e3-b39b-1fae7fb1d011 |
    | instance_id | None                                 |
    | ip          | 172.16.2.60(your IP may be different)|
    | pool        | provider-net                         |
    +-------------+--------------------------------------+
    ```
    >
    Note the floating IP address that was just created.
    
0. **IMPORTANT**: This step requires customization, replace \<FLOATING_IP\> with the floating IP address you created in the above step.

    `student@controller (chester) :~$` `openstack ip floating add <FLOATING_IP> vt2`

0. Okay, just SSH into cirros, again using the \<FLOATING_IP\> you used in the last step.

    `student@controller (chester) :~$` `ssh cirros@<FLOATING_IP>`

0. Type **yes** to continue connecting.

    ```
    Are you sure you want to continue connecting (yes/no)? yes
    ```
    
0. Type the password **cubswin:)** be sure to use the smiley face. Also, the password will not show up as you type.

0. Install a filesystem (assuming the drive is /dev/vdb)

    `$` `sudo mkfs.ext4 /dev/vdb`

0. Create a directory to serve as the mount point

    `$` `sudo mkdir -p /mnt/cargobay`

0. Mount the new directory

    `$` `sudo mount /dev/vdb /mnt/cargobay`

0. Who are you?

    `$` `whoami`

0. change the owner of cargo bay so you can easily add files as user = whoami

    `$` `sudo chown -R cirros  /mnt/cargobay/`

0. Change directory into the newly mounted volume

    `$` `cd /mnt/cargobay`

0. Add a test message to /mnt/cargobay (your present location) with the following command.

    `$` `echo "This is a test message written to my cargo bay volume!" > test.txt`

0. Confirm that your file is there
  
    `$` `ls -l`

0. Unmount the volume in preperation for moving it to a new instance. **(VERY IMPORANT)**

    `$` `cd`     <-- be sure to issue this command first, otherwise you cannot unmount (can't saw off a limb you're standing on!)

0. Unmount the cargobay

    `$` `sudo umount /mnt/cargobay`

0. Exit your SSH session to vt2, and return to the controller.

    `$` `exit`

0. Discover the vault-tek-network ID. The addition of *-F id -F name* to the *neutron net-list* command will only display the id field (column) and name field (column).

    `student@controller (chester) :~$` `neutron net-list -F id -F name`

    ```
    +--------------------------------------+-------------------+
    | id                                   | name              |
    +--------------------------------------+-------------------+
    | 42d302d3-a4e1-42d6-8ff9-bacda83e7e0b | vault-tek-network |
    | b3b8d8f8-6668-48dc-b97e-db92be7c6fc7 | provider-net      |
    +--------------------------------------+-------------------+
    ```
    > Note your UUID value of the vault-tek-network in the output, **not** the one from the above example.  
    
0. **IMPORTANT**: You need to customize this step, which will start a new instance. You'll need to insert your *custom UUID of vault-tek-network* below because this one is **just an example**.

    `student@controller (chester) :~$` `openstack server create --flavor m1.tiny --image cirros --nic net-id=<UUID_OF_vault-tek-network> --security-group http-ssh vt3`

0. Discover instance IDs, use the grep command to only return lines containing vt3

    `student@controller (chester) :~$` `openstack server list | grep vt3`

    ```
    | dc2f706f-a3c5-4fc4-8a84-bfb46223f05e | vt3       | ACTIVE | vault-tek-network=10.10.0.5              |
    ```
    >
    Note the UUID of vt3. We'll need it shortly.

0. Discover cinder volumes

    `student@controller (chester) :~$` `openstack volume list`

    ```
    +--------------------------------------+--------+--------------+------+-------------+----------+--------------------------------------+
    |                  ID                  | Status | Display Name | Size | Volume Type | Bootable |             Attached to              |
    +--------------------------------------+--------+--------------+------+-------------+----------+--------------------------------------+
    | b9f00354-0df1-4d5f-bc23-6423478cf334 | in-use |  cargo-bay   |  1   |    iscsi    |  false   | fd70c522-28da-4607-9610-af766440ac1a |
    +--------------------------------------+--------+--------------+------+-------------+----------+--------------------------------------+
    ```

0. **IMPORTANT**: This step requires customization. Detach cargo-bay from the vt2 instance, where you'll need to use the UUID of vt3 and the UUID of cargo-bay below.

    `student@controller (chester) :~$` `openstack server remove volume <UUID_OF_INSTANCE_vt3> <UUID_OF_cargo-bay>`

0. Confirm detachment. Repeat this step until you see status change from "detaching" to "Available".

    `student@controller (chester) :~$` `openstack volume list`

    ```
    +--------------------------------------+-----------+--------------+------+-------------+----------+--------------------------------------+
    |                  ID                  |   Status  | Display Name | Size | Volume Type | Bootable |             Attached to              |
    +--------------------------------------+-----------+--------------+------+-------------+----------+--------------------------------------+
    | b9f00354-0df1-4d5f-bc23-6423478cf334 | detaching |  cargo-bay   |  1   |    iscsi    |  false   | fd70c522-28da-4607-9610-af766440ac1a |
    +--------------------------------------+-----------+--------------+------+-------------+----------+--------------------------------------+
    ```

0. **IMPORTANT**: The above status says 'detaching'; status needs to read 'available' before you can continue to attach the volume cargo-bay to the new instance vt3.

    `student@controller (chester) :~$` `openstack server add volume <UUID_OF_INSTANCE_vt3> <UUID_OF_cargo-bay>`
    
0. Confirm attachment.

    `student@controller (chester) :~$` `openstack volume list`
    
    ```
    +--------------------------------------+--------------+--------+------+------------------------------+
    | ID                                   | Display Name | Status | Size | Attached to                  |
    +--------------------------------------+--------------+--------+------+------------------------------+
    | d37ab4c8-786e-4915-a94c-0c5ff5e3c20c | cargo-bay    | in-use |    1 | Attached to vt3 on /dev/vdb  |
    +--------------------------------------+--------------+--------+------+------------------------------+
    ```

0. Time to SSH into vt3 and see that our data is still on the volume. Let's create a *NEW* floating IP to apply to vt3 so that SSH is easy.

    `student@controller (chester) :~$` `openstack ip floating create provider-net`
    
    ```
    +-------------+--------------------------------------+
    | Field       | Value                                |
    +-------------+--------------------------------------+
    | fixed_ip    | None                                 |
    | id          | db2bd097-1c9b-46e3-b39b-1fae7fb1d011 |
    | instance_id | None                                 |
    | ip          | 172.16.2.61(your IP may be different)|
    | pool        | provider-net                         |
    +-------------+--------------------------------------+
    ```
    >
    Note the new floating IP address that was just created.
    
0. **IMPORTANT**: This step requires customization, replace \<FLOATING_IP\> with the floating IP address you created in the above step.

    `student@controller (chester) :~$` `openstack ip floating add <FLOATING_IP> vt3`

0. Okay, just SSH into cirros, again using the \<FLOATING_IP\> you used in the last step.

    `student@controller (chester) :~$` `ssh cirros@<FLOATING_IP>`

0. Type **yes** to continue connecting.

    ```
    Are you sure you want to continue connecting (yes/no)? yes
    ```
    
0. Type the password **cubswin:)** be sure to use the smiley face. Also, the password will not show up as you type.

0. Create a directory to serve as the mount point

    `$` `sudo mkdir -p /mnt/cargobay`

0. Mount the new directory

    `$` `sudo mount /dev/vdb /mnt/cargobay`

0. Find out if your old test.txt is still in the volume! List the contents of the mounted volume.

    `$` `ls /mnt/cargobay`
    
0. There it is!! Our old test.txt file! Let's finish up by printing the contents of test.txt

    `$` `cat /mnt/cargobay/test.txt`
    
0. Exit vt3

    `$` `exit`

0. Good job! That does it for this lab.
